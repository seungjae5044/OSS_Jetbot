{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../Picture Data/logo.png\" alt=\"Header\" style=\"width: 800px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Copyright (C): 2010-2019, Shenzhen Yahboom Tech  \n",
    "@Author: Malloy.Yuan  \n",
    "@Date: 2019-07-17 10:10:02  \n",
    "@LastEditors: Malloy.Yuan  \n",
    "@LastEditTime: 2019-09-17 17:54:19  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import related packages to create camera instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera, Robot\n",
    "from jetbot import bgr8_to_jpeg\n",
    "import PID\n",
    "camera = Camera.instance(width=720, height=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVO_MID = 2180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create related control variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global color_x, color_y, color_radius\n",
    "color_x = color_y = color_radius = 0\n",
    "global target_valuex\n",
    "target_valuex = 2100\n",
    "global target_valuey\n",
    "target_valuey = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an array that stores HSV color gamut color classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "global color_lower\n",
    "color_lower=np.array([156,43,46])\n",
    "global color_upperv\n",
    "color_upper = np.array([180, 255, 255])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a PID Control Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xservo_pid = PID.PositionalPID(1.9, 0.3, 0.35)\n",
    "yservo_pid = PID.PositionalPID(1.5, 0.2, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xservo_pid.SetStepSignal(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a PTZ servo engine instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serial Open!\n"
     ]
    }
   ],
   "source": [
    "from servoserial import ServoSerial\n",
    "servo_device = ServoSerial() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color recognition default array data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x08\\x84\\x00\\n\\x02\\x08\\x00\\x00\\n\\x97'\n"
     ]
    }
   ],
   "source": [
    "color_lower=np.array([156,43,46])\n",
    "color_upper = np.array([180, 255, 255])\n",
    "target_valuex = target_valuey = 2048\n",
    "servo_device.Servo_serial_double_control(1, SERVO_MID, 2, 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set to identify red array data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x08\\x00\\x00\\n\\x02\\x08\\x00\\x00\\n\\x1b'\n"
     ]
    }
   ],
   "source": [
    "color_lower=np.array([0,43,46])\n",
    "color_upper = np.array([10, 255, 255])\n",
    "target_valuex = target_valuey = 2048\n",
    "servo_device.Servo_serial_double_control(1, 2048, 2, 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set to identify yellow array data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x08\\x00\\x00\\n\\x02\\x08\\x00\\x00\\n\\x1b'\n"
     ]
    }
   ],
   "source": [
    "color_lower=np.array([26,43,46])\n",
    "color_upper = np.array([34, 255, 255])\n",
    "target_valuex = 2100\n",
    "target_valuey = 2048\n",
    "servo_device.Servo_serial_double_control(1, 2048, 2, 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set to identify blue array data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x08\\x00\\x00\\n\\x02\\x08\\x00\\x00\\n\\x1b'\n"
     ]
    }
   ],
   "source": [
    "color_lower=np.array([100,43,46])\n",
    "color_upper = np.array([124, 255, 255])\n",
    "target_valuex = 2100\n",
    "target_valuey = 2048\n",
    "servo_device.Servo_serial_double_control(1, 2048, 2, 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set to identify green array data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_lower=np.array([35,43,46])\n",
    "color_upper = np.array([77, 255, 255])\n",
    "target_valuex = 2100\n",
    "target_valuey = 2048\n",
    "servo_device.Servo_serial_double_control(1, 2048, 2, 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set to identify orange array data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "b'\\xff\\xff\\xfe\\x0e\\x83*\\x04\\x01\\x08\\x84\\x00\\n\\x02\\x08\\x00\\x00\\n\\x97'\n"
     ]
    }
   ],
   "source": [
    "color_lower=np.array([11,43,46])\n",
    "color_upper = np.array([25, 255, 255])\n",
    "target_valuex = 2100\n",
    "target_valuey = 2048\n",
    "servo_device.Servo_serial_double_control(1, SERVO_MID, 2, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, k, max_iters=100):\n",
    "    # 데이터 포인트의 수와 특성의 수 확인\n",
    "    m, n = X.shape\n",
    "\n",
    "    # 초기 중심 선택\n",
    "    centroids = X[np.random.choice(m, k, replace=False)]\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "       \n",
    "        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "\n",
    "        # 중심 재계산\n",
    "        new_centroids = np.array([X[labels == j].mean(axis=0) for j in range(k)])\n",
    "\n",
    "        # 수렴 여부 확인\n",
    "        if np.all(centroids == new_centroids):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    return centroids, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main process of PTZ movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a display control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aed47e9c61c4b21a3175bf55c8f0623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='300', width='300')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "color_image = widgets.Image(format='jpeg', width=300, height=300)\n",
    "display(color_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = camera.value\n",
    "frame_c = frame.reshape(-1,3)\n",
    "data = frame_c\n",
    "k = 5\n",
    "centroids, labels = kmeans(data, k)\n",
    "labels, counts = np.unique(labels, return_counts=True)\n",
    "cen = labels[counts.argmax()]\n",
    "mask_color = centroids[cen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) /home/nvidia/host/build_opencv/nv_opencv/modules/imgproc/src/shapedescr.cpp:274: error: (-215:Assertion failed) npoints >= 0 && (depth == CV_32F || depth == CV_32S) in function 'contourArea'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-bd3d771c24e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcnts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETR_EXTERNAL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mcolor_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor_radius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminEnclosingCircle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcolor_radius\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.1) /home/nvidia/host/build_opencv/nv_opencv/modules/imgproc/src/shapedescr.cpp:274: error: (-215:Assertion failed) npoints >= 0 && (depth == CV_32F || depth == CV_32S) in function 'contourArea'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frame = cv2.resize(frame, (300, 300))\n",
    "frame_=cv2.GaussianBlur(frame,(5,5),0)                 \n",
    "hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "mask=cv2.inRange(hsv,color_lower,color_upper)\n",
    "mask=cv2.erode(mask,None,iterations=2)\n",
    "mask=cv2.dilate(mask,None,iterations=2)\n",
    "mask=cv2.GaussianBlur(mask,(3,3),0)\n",
    "cnts=cv2.findContours(mask.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "if len(cnts)>0:\n",
    "    cnt = max (cnts,key=cv2.contourArea)\n",
    "    (color_x,color_y),color_radius=cv2.minEnclosingCircle(cnt)\n",
    "if color_radius > 10:\n",
    "    # Mark the detected color\n",
    "    cv2.circle(frame,(int(color_x),int(color_y)),int(color_radius),(255,0,255),2)\n",
    "color_image.value = bgr8_to_jpeg(frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-12e647dce69d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mframe_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhsv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while 1:\n",
    "    frame = camera.value\n",
    "    frame = cv2.resize(frame, (300, 300))\n",
    "    frame_=cv2.GaussianBlur(frame,(5,5),0)                    \n",
    "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    mask=cv2.inRange(hsv,color_lower,color_upper)  \n",
    "    mask=cv2.erode(mask,None,iterations=2)\n",
    "    mask=cv2.dilate(mask,None,iterations=2)\n",
    "    mask=cv2.GaussianBlur(mask,(3,3),0)     \n",
    "    cnts=cv2.findContours(mask.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2] \n",
    "    if len(cnts)>0:\n",
    "        cnt = max (cnts,key=cv2.contourArea)\n",
    "        (color_x,color_y),color_radius=cv2.minEnclosingCircle(cnt)\n",
    "    if color_radius > 10:\n",
    "        # Mark the detected color\n",
    "        cv2.circle(frame,(int(color_x),int(color_y)),int(color_radius),(255,0,255),2)  \n",
    "        #Proportion-Integration-Differentiation\n",
    "        xservo_pid.SystemOutput = color_x\n",
    "        \n",
    "\n",
    "        target_x = 150\n",
    "        target_y = 150\n",
    "        speed = 0.8\n",
    "        turn = np.abs(target_x-color_x)/300\n",
    "        if color_x < target_x - 60:\n",
    "            robot.set_motors(speed-turn, speed)\n",
    "        elif color_x > target_x + 60:\n",
    "            robot.set_motors(speed, speed-turn)\n",
    "        elif color_radius>50:\n",
    "            robot.stop()\n",
    "        else:\n",
    "            robot.set_motors(speed, speed)\n",
    "# Real-time return of image data for display\n",
    "    color_image.value = bgr8_to_jpeg(frame)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xservo_pid.SetStepSignal(150)\n",
    "        xservo_pid.SetInertiaTime(0.01, 0.006)\n",
    "        target_valuex = int(2048+xservo_pid.SystemOutput)\n",
    "        # Input Y axis direction parameter PID control input\n",
    "        yservo_pid.SystemOutput = color_y\n",
    "        yservo_pid.SetStepSignal(150)\n",
    "        yservo_pid.SetInertiaTime(0.01, 0.006)\n",
    "        target_valuey = int(2048+yservo_pid.SystemOutput)\n",
    "        # Rotate the gimbal to the PID adjustment position\n",
    "        servo_device.Servo_serial_double_control( 1, target_valuex, 2, target_valuey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
